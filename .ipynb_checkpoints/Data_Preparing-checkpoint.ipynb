{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the qapair.txt \n",
    "# File qapair.txt is in this format : \n",
    "# Question_id , Answer0_vote , Answer1_vote , ... , NumOfAnswer\n",
    "def generate_qapair(PATH_IN, PATH_OUT):\n",
    "    \n",
    "    # f_in  = open(PATH_IN + 'answer.json', 'r')\n",
    "    # f_out = open(PATH_OUT + 'qapair.txt', 'w') \n",
    "    \n",
    "    with open(PATH_IN + 'answer.json' , 'r') as f_in, \\\n",
    "         open(PATH_OUT + 'qapair.txt' , 'w') as f_out :\n",
    "            \n",
    "            line1 = f_in.readline()\n",
    "            info1 = line1.split('\"')\n",
    "            pre_qid = info1[3]\n",
    "            pre_vote = info1[-2]\n",
    "            f_out.write(pre_qid+','+pre_vote)\n",
    "\n",
    "            num_vote = 0\n",
    "            for line in f_in:\n",
    "                info = line.split('\"')\n",
    "                cur_qid = info[3]\n",
    "                # print cur_qid\n",
    "                cur_vote = info[-2]\n",
    "                if cur_qid == pre_qid :\n",
    "                    f_out.write(','+cur_vote)\n",
    "                    num_vote = num_vote + 1\n",
    "                else :\n",
    "                    f_out.write(','+str(num_vote + 1))\n",
    "                    num_vote = 0\n",
    "                    f_out.write('\\n'+cur_qid+','+cur_vote)\n",
    "                pre_qid = cur_qid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract numOfAnswer >= 3 qid write to qid_3more\n",
    "# extract numOfAnswer < 3 qid write to qid_3less\n",
    "def extract_qid(PATH_IN, PATH_OUT) :\n",
    "\n",
    "    #f_in = open(PATH_IN + 'qapair.txt', 'r')\n",
    "    #f_out = open(PATH_OUT + 'qid_ex.txt', 'w')    \n",
    "    \n",
    "    with open(PATH_IN + 'qapair.txt', 'r') as f_in, \\\n",
    "    open(PATH_OUT + 'qid_3more.txt', 'w') as f_out1,     \\\n",
    "    open(PATH_OUT + 'qid_3less.txt', 'w') as f_out2:\n",
    "        examples = 0\n",
    "        for line in f_in:\n",
    "\n",
    "            info = line.split(',')\n",
    "            qid = info[0]\n",
    "            num_answer = info[-1]\n",
    "\n",
    "            if int(num_answer) >= 3:\n",
    "                # print num_a\n",
    "                # examples = examples + 1        \n",
    "                f_out1.write(qid+'\\n')\n",
    "                # print qid`\n",
    "            else :\n",
    "                f_out2.write(qid+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split question.json into \n",
    "# question_train.json (numOfAnswer >= 3 )\n",
    "# question_test.sjon (numOfAnswer < 3 )\n",
    "def split_qustion(PATH_IN, PATH_OUT) :\n",
    "\n",
    "    with open(PATH_IN + 'qid_3more.txt', 'r') as f,         \\\n",
    "        open(PATH_IN + 'question.json', 'r') as f_in,      \\\n",
    "        open(PATH_IN + 'question_train.json', 'w') as f_out1, \\\n",
    "        open(PATH_IN + 'question_test.json', 'w') as f_out2: \n",
    "        qid_list = [line.strip() for line in f]\n",
    "\n",
    "        # f_in = open(PATH_IN + 'question.json', 'r')\n",
    "        # f_out = open(PATH_OUT + 'question_filtered.json', 'w')\n",
    "\n",
    "        for line in f_in:\n",
    "            info = line.split('\"')\n",
    "            qid = info[-2]\n",
    "            if qid in qid_list:\n",
    "                # print qid\n",
    "                f_out1.write(line)\n",
    "            else :\n",
    "                f_out2.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_strip(data) :\n",
    "    data = data.str.replace('\\n','')\n",
    "    data = data.str.replace('\\r','')\n",
    "    data = data.str.replace(',',' ')\n",
    "    data = data.str.replace('.','')\n",
    "    data = data.str.replace('\"','')\n",
    "    data = data.str.lower()   \n",
    "    return data  \n",
    "\n",
    "def format_train_data(PATH_IN, PATH_OUT, FILE):\n",
    "    \n",
    "    with open(PATH_IN + 'answer.json', 'r') as f1, \\\n",
    "        open(PATH_IN + 'question_train.json', 'r') as f2, \\\n",
    "        open(PATH_IN + 'user.json', 'r') as f3, \\\n",
    "        open(PATH_IN + 'qtags.json', 'r') as f4 :\n",
    "    \n",
    "            answer = [json.loads(line.strip().strip(',')) for line in f1]\n",
    "            #print answer[0]\n",
    "            #answer_frame \n",
    "            answer_frame = DataFrame(answer)\n",
    "            answer_frame = answer_frame.drop_duplicates('answer_id')\n",
    "            #print answer_frame #14464 x 5\n",
    "\n",
    "            question = [json.loads(line.strip().strip(',')) for line in f2]\n",
    "            #print question[0]\n",
    "            question_frame = DataFrame(question)\n",
    "            question_frame = question_frame.drop_duplicates('question_id')\n",
    "            #print question_frame  # 898 x 2\n",
    "\n",
    "            user = [json.loads(line.strip().strip(',')) for line in f3]\n",
    "            user_frame = DataFrame(user)\n",
    "            user_frame = user_frame.drop_duplicates('user_id')\n",
    "            #print user_frame    # 3378 x 14\n",
    "\n",
    "            qtag = [json.loads(line.strip().strip(',')) for line in f4]\n",
    "            qtag_frame = DataFrame(qtag)\n",
    "            qtag_frame = qtag_frame.drop_duplicates('question_id')\n",
    "            #print qtag_frame      # 9999 x 2\n",
    "\n",
    "            # Generate the source data\n",
    "            m1 = pd.merge(answer_frame, user_frame, how = 'outer')\n",
    "            m1 = m1.rename(columns = {'related_id':'question_id'})\n",
    "            #print m1.head()    # 14781 x 18\n",
    "\n",
    "            m2 = pd.merge(qtag_frame, question_frame)\n",
    "            #print m2.head()     # 898 x 3 \n",
    "\n",
    "            # Generate \n",
    "            m = pd.merge(m1, m2, on = 'question_id')\n",
    "            #print m\n",
    "            m = m.sort(['question_id','answer_voted'], ascending=[1,0])\n",
    "            m = m.drop('user_address', axis=1)\n",
    "            m = m.drop('user_name', axis=1)\n",
    "            m = m.reset_index(drop=True)\n",
    "            #print m\n",
    "\n",
    "            # modify the string in dataframe m\n",
    "            m['answer_content'] = str_strip(m['answer_content'])\n",
    "            m['question_content'] = str_strip(m['question_content'])\n",
    "            m['user_edu'] = str_strip(m['user_edu'])\n",
    "            m['user_specialty'] = str_strip(m['user_specialty'])\n",
    "            m['user_interest'] = str_strip(m['user_interest'].astype(str))\n",
    "            m['user_intro'] = str_strip(m['user_intro'])\n",
    "            m['question_tags'] = str_strip(m['question_tags'].astype(str))\n",
    "            m['user_recommends'] = str_strip(m['user_recommends'].astype(str))\n",
    "            \n",
    "            # print m      # 3195 x 20\n",
    "            # m.to_json(PATH_OUT + 'total01.json')\n",
    "\n",
    "            m.to_csv(PATH_OUT + FILE + '_Train.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_test_data(PATH_IN, PATH_OUT, FILE):\n",
    "    \n",
    "    with open(PATH_IN + 'answer.json', 'r') as f1, \\\n",
    "        open(PATH_IN + 'question_test.json', 'r') as f2, \\\n",
    "        open(PATH_IN + 'user.json', 'r') as f3, \\\n",
    "        open(PATH_IN + 'qtags.json', 'r') as f4 :\n",
    "    \n",
    "            answer = [json.loads(line.strip().strip(',')) for line in f1]\n",
    "            #print answer[0]\n",
    "            #answer_frame \n",
    "            answer_frame = DataFrame(answer)\n",
    "            answer_frame = answer_frame.drop_duplicates('answer_id')\n",
    "            #print answer_frame #14464 x 5\n",
    "\n",
    "            question = [json.loads(line.strip().strip(',')) for line in f2]\n",
    "            #print question[0]\n",
    "            question_frame = DataFrame(question)\n",
    "            question_frame = question_frame.drop_duplicates('question_id')\n",
    "            #print question_frame  # 898 x 2\n",
    "\n",
    "            user = [json.loads(line.strip().strip(',')) for line in f3]\n",
    "            user_frame = DataFrame(user)\n",
    "            user_frame = user_frame.drop_duplicates('user_id')\n",
    "            #print user_frame    # 3378 x 14\n",
    "\n",
    "            qtag = [json.loads(line.strip().strip(',')) for line in f4]\n",
    "            qtag_frame = DataFrame(qtag)\n",
    "            qtag_frame = qtag_frame.drop_duplicates('question_id')\n",
    "            #print qtag_frame      # 9999 x 2\n",
    "\n",
    "            # Generate the source data\n",
    "            m1 = pd.merge(answer_frame, user_frame, how = 'outer')\n",
    "            m1 = m1.rename(columns = {'related_id':'question_id'})\n",
    "            #print m1.head()    # 14781 x 18\n",
    "\n",
    "            m2 = pd.merge(qtag_frame, question_frame)\n",
    "            #print m2.head()     # 898 x 3 \n",
    "\n",
    "            # Generate \n",
    "            m = pd.merge(m1, m2, on = 'question_id')\n",
    "            #print m\n",
    "            m = m.sort(['question_id','answer_voted'], ascending=[1,0])\n",
    "            m = m.drop('user_address', axis=1)\n",
    "            m = m.drop('user_name', axis=1)\n",
    "            m = m.reset_index(drop=True)\n",
    "            #print m\n",
    "\n",
    "            # modify the string in dataframe m\n",
    "            m['answer_content'] = str_strip(m['answer_content'])\n",
    "            m['question_content'] = str_strip(m['question_content'])\n",
    "            m['user_edu'] = str_strip(m['user_edu'])\n",
    "            m['user_specialty'] = str_strip(m['user_specialty'])\n",
    "            m['user_interest'] = str_strip(m['user_interest'].astype(str))\n",
    "            m['user_intro'] = str_strip(m['user_intro'])\n",
    "            m['question_tags'] = str_strip(m['question_tags'].astype(str))\n",
    "            m['user_recommends'] = str_strip(m['user_recommends'].astype(str))\n",
    "            \n",
    "            # print m      # 3195 x 20\n",
    "            # m.to_json(PATH_OUT + 'total01.json')\n",
    "\n",
    "            m.to_csv(PATH_OUT + FILE + '_Test.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Data_Preparing(PATH_IN, PATH_OUT, FILE) :\n",
    "    \n",
    "    # RUN the function in pipline\n",
    "    generate_qapair(PATH_IN, PATH_OUT)\n",
    "    extract_qid(PATH_IN, PATH_OUT)\n",
    "    split_qustion(PATH_IN, PATH_OUT)\n",
    "    format_train_data(PATH_IN, PATH_OUT, FILE)\n",
    "    format_test_data(PATH_IN, PATH_OUT, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILE = 'Allergy'\n",
    "# FILE = 'Depression'\n",
    "# FILE = 'Alzheimer'\n",
    "FILE = 'Arthritis'\n",
    "PATH_IN  = './' + FILE + '/'\n",
    "PATH_OUT = './' + FILE + '/'\n",
    "\n",
    "Data_Preparing(PATH_IN, PATH_OUT, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File_Type = 'Train'\n",
    "File_Type = 'Test'\n",
    "\n",
    "\n",
    "file_list = [   './Allergy/Allergy_' + File_Type +'.csv',\n",
    "                './Depression/Depression_' + File_Type + '.csv',\n",
    "                './Arthritis/Arthritis_' + File_Type +'.csv',\n",
    "                './Alzheimer/Alzheimer_' + File_Type +'.csv' ]\n",
    "\n",
    "# print train_files\n",
    "\n",
    "def load_data(file_list):\n",
    "    with open('./Total_' + File_Type + '.csv','w') as outfile:\n",
    "        for fname in file_list:\n",
    "            with open(fname) as infile:\n",
    "                outfile.write(infile.read())   \n",
    "\n",
    "load_data(file_list)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
